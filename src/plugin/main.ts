
import type {AugmentedEnum, AugmentedMessage} from './env';

import {ode, type Dict, odv} from '@blake.regalia/belt';


import {NeutrinoImpl} from './impl-neutrino';
import {plugin} from './plugin';
import {importModule, print} from './ts-factory';

// inject into preamble of any file, allow linter to delete unused imports
const A_GLOBAL_PREAMBLE = [
	`/*
	* ${'='.repeat(32)}
	*     GENERATED FILE WARNING
	* Do not edit this file manually.
	* ${'='.repeat(32)}
	*/`.replace(/\n\t+/g, '\n'),
	...[
		importModule('@blake.regalia/belt', [
			'F_IDENTITY',
			'__UNDEFINED',
			'base64_to_buffer',
			'text_to_buffer',
		]),
		importModule('#/util', [
			'safe_buffer_to_base64',
			'safe_buffer_to_text',
		]),
		importModule('#/protobuf-writer', [
			'Protobuf',
			'map',
			'temporal',
			'any',
			'coin',
			'coins',
		]),
		importModule('#/protobuf-reader', [
			'decode_protobuf',
			'decode_protobuf_r0',
			'decode_protobuf_r0_0',
			'decode_coin',
			'reduce_temporal',
		]),
		importModule('#/transport', [
			'F_RPC_REQ_NO_ARGS',
			'restful_grpc',
		]),
		importModule('#/types', [
			'WeakInt64Str',
			'WeakUint64Str',
			'WeakInt128Str',
			'WeakUint128Str',
			'Int64Str',
			'Uint64Str',
			'Int128Str',
			'Uint128Str',
			'WeakAccountAddr',
			'WeakValidatorAddr',
			'AccountAddr',
			'ValidatorAddr',
			'HexLower',
			'ImplementsInterface',
			'Encoded',
		], true),
	].map(yn => print(yn)),
];


export const main = () => {
	void plugin((a_protos, h_inputs, h_types) => {
		// new impl
		const k_impl = new NeutrinoImpl(h_types);

		// const h_drafts: Dict<

		const h_outputs: Dict<string> = {};

		// [typePath: string]: serialized encoders
		const h_encoders: Dict<{
			message: AugmentedMessage;
			encoder: string;
		}> = {};

		// 
		const h_closure: Dict<AugmentedMessage> = {};
		const h_enums: Dict<AugmentedEnum> = {};

		/**
		 * add closures from given message type
		 */
		function mark_fields(g_msg: AugmentedMessage) {
			// ensure every field's type has an encoder
			for(const g_field of g_msg.fieldList) {
				// ref type path
				const si_type = g_field.typeName;

				// type exists, is not encoded, and is not yet defined in closure/enum
				if(si_type && !h_encoders[si_type] && !h_closure[si_type] && !h_enums[si_type]) {
					// resolve type
					const g_resolved = h_types[si_type];

					// message
					if('message' === g_resolved.form) {
						h_closure[si_type] = g_resolved;

						// recurse on message
						mark_fields(g_resolved);
					}
					// enum
					else {
						h_enums[si_type] = g_resolved;
					}
				}
			}
		}


		const h_tmps: Dict<{
			a_gateways: string[];
			a_anys: string[];
			a_decoders: string[];
		}> = {};

		// each proto file
		for(const g_proto of a_protos) {
			// reset instance's internal file stuff
			k_impl.open(g_proto);

			// new string lists
			const a_gateways: string[] = [];
			const a_anys: string[] = [];
			const a_decoders: string[] = [];

			h_tmps[k_impl.path] = {
				a_gateways,
				a_anys,
				a_decoders,
			};

			// each top-level messages
			for(const g_msg of g_proto.messageTypeList) {
				// ref message options
				const g_opts = g_msg.options;

				// implements interface
				if(g_opts?.implementsInterfaceList) {
					// produce 'any' encoder
					a_anys.push(k_impl.anyEncoder(g_msg));

					// ensure its fields can be encoded
					mark_fields(g_msg);
				}
			}

			// each service
			for(const g_service of g_proto.serviceList) {
				// find longest path prefix
				let s_path_prefix = '';
				{
					// each method (pre-gen)
					for(const g_method of g_service.methodList) {
						const g_opts = g_method.options;
						const g_http = g_opts?.http;

						// only interested in GET or POST
						const sr_path = g_http?.get || g_http?.post;

						// no path; skip
						if(!sr_path) continue;

						// initialize
						if(!s_path_prefix) {
							s_path_prefix = sr_path;
							const i_param = sr_path.indexOf('{');
							if(i_param >= 0) s_path_prefix = sr_path.slice(0, sr_path.indexOf('{'));
						}
						// find common substring
						else {
							// each character
							for(let i_char=0; i_char<Math.min(s_path_prefix.length, sr_path.length); i_char++) {
								// end of common substring
								if(sr_path[i_char] !== s_path_prefix[i_char]) {
									s_path_prefix = sr_path.slice(0, i_char);
									break;
								}
							}
						}
					}
				}

				// each method
				for(const g_method of g_service.methodList) {
					// skip functions missing input or output type
					if(!g_method.inputType || !g_method.outputType) continue;
					const {
						inputType: sr_input,
						outputType: sr_output,
					} = g_method;

					// locate rpc input
					const g_input = h_types[sr_input];
					if('message' !== g_input?.form) throw new Error(`Failed to find rpc input ${sr_input} in ${g_proto.name!}`);

					// locate rpc output
					const g_output = h_types[sr_output];
					if('message' !== g_output?.form) throw new Error(`Failed to find rpc output ${sr_output}`);

					// gRPC-gateway method
					const g_http = g_method.options?.http;
					if(g_http?.get || g_http?.post) {
						const sx_gateway = k_impl.gateway(
							s_path_prefix,
							g_method,
							g_input,
							g_output
						);

						a_gateways.push(sx_gateway);
					}
					// otherwise, ensure user can encode method inputs and decode method outputs
					else {
						// add input encoder
						h_encoders[g_input.path] = {
							message: g_input,
							encoder: k_impl.msgEncoder(g_input),
						};

						// ensure its fields can be encoded
						mark_fields(g_input);

						// message has output content
						if(g_output.fieldList.length) {
							// add output decoder
							const sx_decoder = k_impl.msgDecoder(g_output);

							// closure is not needed since decoder handles everything
							if(sx_decoder) a_decoders.push(sx_decoder);
						}
					}
				}
			}
		}

		debugger;

		// each message in need of an encoder
		for(const [, g_msg] of ode(h_closure)) {
			// open message's source
			k_impl.open(g_msg.source);

			// add encoder
			h_encoders[g_msg.path] = {
				message: g_msg,
				encoder: k_impl.msgEncoder(g_msg),
			};

			// 	// normal message
			// 	else {
			// 		// produce encoder but 
			// 		a_encoders.push(k_impl.msgEncoder(g_msg));
			// 	}

			// 	// recurse on nested types
			// 	gen_encoders(g_msg.nestedTypeList);
			// function gen_encoders(a_msgs: AugmentedMessage[]) {
			// 	for(const g_msg of a_msgs) {
			// 		// ref message options
			// 		const g_opts = g_msg.options;

			// 		// implements interface; produce 'any' encoder
			// 		if(g_opts?.implementsInterfaceList) {
			// 			a_encoders.push(k_impl.anyEncoder(g_msg)!);
			// 		}
			// 		// normal message
			// 		else {
			// 			// produce encoder but 
			// 			a_encoders.push(k_impl.msgEncoder(g_msg));
			// 		}

			// 		// recurse on nested types
			// 		gen_encoders(g_msg.nestedTypeList);

			// 		// // recurse on nested enums
			// 		// gen_enums(g_msg.enumTypeList);
			// 	}
			// }
		}


		// every file
		for(const [, g_proto] of ode(h_inputs)) {
			// open
			k_impl.open(g_proto);

			const {
				a_gateways,
				a_anys,
				a_decoders,
			} = h_tmps[k_impl.path] || {};

			// body
			const a_body: string[] = [];

			// prep file parts
			const g_parts = {
				head: [
					...A_GLOBAL_PREAMBLE,
					...k_impl.imports(),
				],
				body: a_body,
			};

			// lcd methods
			if(a_gateways?.length) {
				g_parts.head.push(...k_impl.head('lcd'));

				a_body.push(
					...k_impl.body('lcd'),
					...a_gateways
				);
			}

			// anys
			if(a_anys?.length) {
				g_parts.head.push(...k_impl.head('any'));

				a_body.push(
					...k_impl.body('any'),
					...a_anys
				);
			}

			// encoders
			const a_encoders: string[] = [];
			for(const g_encoder of odv(h_encoders)) {
				if(g_proto === g_encoder.message.source) {
					a_encoders.push(g_encoder.encoder);
				}
			}

			if(a_encoders.length) {
				g_parts.head.push(...k_impl.head('encoder'));

				a_body.push(
					...k_impl.body('encoder'),
					...a_encoders
				);
			}

			// decoders
			if(a_decoders?.length) {
				g_parts.head.push(...k_impl.head('decoder'));

				a_body.push(
					...k_impl.body('decoder'),
					...a_decoders
				);
			}

			// there are contents to write to the file
			if(a_body.length) {
				h_outputs[k_impl.path] = [g_parts.head.join('\n'), ...g_parts.body].join('\n\n');
			}
		}

		debugger;

		// // process closures
		// let h_search = h_closure;
		// for(;;) {
		// 	const h_discovered: Dict<AugmentedMessage> = {};

		// 	for(const [, g_msg] of ode(h_search)) {
		// 		// each field in message
		// 		for(const g_field of g_msg.fieldList) {
		// 			const si_type = g_field.typeName!;

		// 			// not yet in closure/dicosvered
		// 			if(si_type && !h_closure[si_type] && !h_discovered[si_type]) {
		// 				// resolve
		// 				const g_resolved = k_impl.resolveType(si_type);

		// 				// message
		// 				if('fieldList' in g_resolved) {
		// 					h_discovered[si_type] = g_resolved;
		// 				}
		// 				// enum
		// 				else {
		// 					h_enums[si_type] = g_resolved;
		// 				}
		// 			}
		// 		}
		// 	}

		// 	// new messages were discovered
		// 	if(Object.keys(h_discovered).length) {
		// 		// merge with closure
		// 		Object.assign(h_closure, h_discovered);

		// 		// repeat search on newly discovered ones
		// 		h_search = h_discovered;
		// 	}
		// 	else {
		// 		break;
		// 	}
		// }

		// // each closure type
		// for(const [, g_msg] of ode(h_closure)) {
		// 	k_impl.msgEncoder(g_msg);
		// }


		return h_outputs;
	});
};
